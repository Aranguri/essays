{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural nets 2\n",
    "Here we are analyzing more complex concepts about neural nets.\n",
    "\n",
    "### Normalization\n",
    "#### Idea of normalizing\n",
    "We can picture the error surface as a bowl. This bowl can be elongated or stretched. In those cases, the gradient doesn't point towards the center of the bowl (the minimum.) Instead, it's more concerned about the ladder. We can see this in the diagram below. The lines represent the level curves [#]. The x represents a set of weights and the arrow the gradient."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hide_egal": true,
    "is_egal": true
   },
   "source": [
    "<svg height=\"250\" width=\"100%\"><desc>Created with Snap</desc><defs><filter id=\"Sjmjc2b2f3\" filterUnits=\"userSpaceOnUse\"><feGaussianBlur in=\"SourceAlpha\" stdDeviation=\"3\"></feGaussianBlur><feOffset dx=\"0\" dy=\"2\" result=\"offsetblur\"></feOffset><feFlood flood-color=\"#000000\"></feFlood><feComposite in2=\"offsetblur\" operator=\"in\"></feComposite><feComponentTransfer><feFuncA type=\"linear\" slope=\"1\"></feFuncA></feComponentTransfer><feMerge><feMergeNode></feMergeNode><feMergeNode in=\"SourceGraphic\"></feMergeNode></feMerge></filter><marker viewBox=\"0 0 10 10\" markerWidth=\"10\" markerHeight=\"10\" orient=\"auto\" refX=\"9\" refY=\"3\" id=\"arrowEndMarker\"><polygon points=\"0,0,0,6,9,3,0,0\" fill=\"#323232\" id=\"arrow\" style=\"\"></polygon></marker><marker viewBox=\"0 0 10 10\" markerWidth=\"10\" markerHeight=\"10\" orient=\"auto\" refX=\"0\" refY=\"3\" id=\"arrowStartMarker\"><polygon points=\"0,3,9,0,9,6,0,3\" fill=\"#323232\" id=\"startArrow\" style=\"\"></polygon></marker><filter id=\"Sjo0b23cd3\" filterUnits=\"userSpaceOnUse\"><feGaussianBlur in=\"SourceAlpha\" stdDeviation=\"3\"></feGaussianBlur><feOffset dx=\"0\" dy=\"2\" result=\"offsetblur\"></feOffset><feFlood flood-color=\"#000000\"></feFlood><feComposite in2=\"offsetblur\" operator=\"in\"></feComposite><feComponentTransfer><feFuncA type=\"linear\" slope=\"1\"></feFuncA></feComponentTransfer><feMerge><feMergeNode></feMergeNode><feMergeNode in=\"SourceGraphic\"></feMergeNode></feMerge></filter><marker viewBox=\"0 0 10 10\" markerWidth=\"10\" markerHeight=\"10\" orient=\"auto\" refX=\"9\" refY=\"3\" id=\"arrowEndMarker\"><polygon points=\"0,0,0,6,9,3,0,0\" fill=\"#323232\" id=\"arrow\" style=\"\"></polygon></marker><marker viewBox=\"0 0 10 10\" markerWidth=\"10\" markerHeight=\"10\" orient=\"auto\" refX=\"0\" refY=\"3\" id=\"arrowStartMarker\"><polygon points=\"0,3,9,0,9,6,0,3\" fill=\"#323232\" id=\"startArrow\" style=\"\"></polygon></marker></defs><g id=\"drup_elem_1\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><circle cx=\"413.5\" cy=\"128.15625\" r=\"41\" vector-effect=\"non-scaling-stroke\" fill=\"#ffffff\" stroke=\"#000000\" style=\"stroke-width: 1;\" class=\"core alignable sub\" transform=\"matrix(3.6426,0,0,1,-982.209,-11)\"></circle><circle cx=\"413.5\" cy=\"87.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_1_endpoint_0\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint up sub\" transform=\"matrix(1,0,0,1,110.4931,-11)\"></circle><circle cx=\"413.5\" cy=\"169.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_1_endpoint_1\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint down sub\" transform=\"matrix(1,0,0,1,110.4931,-11)\"></circle><circle cx=\"372.5\" cy=\"128.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_1_endpoint_2\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint left sub\" transform=\"matrix(1,0,0,1,2.1477,-11)\"></circle><circle cx=\"454.5\" cy=\"128.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_1_endpoint_3\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint right sub\" transform=\"matrix(1,0,0,1,218.8384,-11)\"></circle><text x=\"413.5\" y=\"128.15625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\" transform=\"matrix(1,0,0,1,110.4518,-11)\">|</text></g><g id=\"drup_elem_6\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><circle cx=\"402.5\" cy=\"115.15625\" r=\"31\" vector-effect=\"non-scaling-stroke\" fill=\"#ffffff\" stroke=\"#000000\" style=\"stroke-width: 1;\" class=\"core alignable sub\" transform=\"matrix(3.4801,0,0,1,-886.2397,2)\"></circle><circle cx=\"402.5\" cy=\"84.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_6_endpoint_0\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint up sub\" transform=\"matrix(1,0,0,1,111.9997,2)\"></circle><circle cx=\"402.5\" cy=\"146.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_6_endpoint_1\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint down sub\" transform=\"matrix(1,0,0,1,111.9997,2)\"></circle><circle cx=\"371.5\" cy=\"115.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_6_endpoint_2\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint left sub\" transform=\"matrix(1,0,0,1,35.1167,2)\"></circle><circle cx=\"433.5\" cy=\"115.15625\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_6_endpoint_3\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint right sub\" transform=\"matrix(1,0,0,1,188.8827,2)\"></circle><text x=\"402.5\" y=\"115.15625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\" transform=\"matrix(1,0,0,1,111.9609,2)\">|</text></g><g id=\"drup_elem_9\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"450.5\" x2=\"456.5\" y1=\"75.15625\" y2=\"86.15625\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"453.5\" y=\"80.65625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_10\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"459.5\" x2=\"449.5\" y1=\"76.15625\" y2=\"86.15625\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"454.5\" y=\"81.15625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_11\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"451.5\" x2=\"456.5\" y1=\"80.15625\" y2=\"105.15625\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"454\" y=\"92.65625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0; visibility: visible;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_12\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"457.5\" x2=\"461.5\" y1=\"105.15625\" y2=\"101.15625\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"459.5\" y=\"103.15625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_13\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"456.5\" x2=\"451.5\" y1=\"105.15625\" y2=\"103.15625\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"454\" y=\"104.15625\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_14\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><circle cx=\"440.5\" cy=\"105.34375\" r=\"23\" vector-effect=\"non-scaling-stroke\" fill=\"#ffffff\" stroke=\"#000000\" style=\"stroke-width: 1;\" class=\"core alignable sub\" transform=\"matrix(3.2358,0,0,0.7174,-912.3677,42.2711)\"></circle><circle cx=\"440.5\" cy=\"82.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_14_endpoint_0\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint up sub\" transform=\"matrix(1,0,0,1,72.4962,19)\"></circle><circle cx=\"440.5\" cy=\"128.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_14_endpoint_1\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint down sub\" transform=\"matrix(1,0,0,1,72.4962,6)\"></circle><circle cx=\"417.5\" cy=\"105.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_14_endpoint_2\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint left sub\" transform=\"matrix(1,0,0,1,21.0731,12.5)\"></circle><circle cx=\"463.5\" cy=\"105.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_14_endpoint_3\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint right sub\" transform=\"matrix(1,0,0,1,123.9194,12.5)\"></circle><text x=\"440.5\" y=\"105.34375\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0; visibility: visible;\" class=\"egal-label sub\" transform=\"matrix(1,0,0,1,72.4613,12.5)\">|</text></g><g id=\"drup_elem_15\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><circle cx=\"495.5\" cy=\"111.34375\" r=\"11\" vector-effect=\"non-scaling-stroke\" fill=\"#ffffff\" stroke=\"#000000\" style=\"stroke-width: 1;\" class=\"core alignable sub\" transform=\"matrix(3.3599,0,0,0.8636,-1158.3036,19.6801)\"></circle><circle cx=\"495.5\" cy=\"100.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_15_endpoint_0\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint up sub\" transform=\"matrix(1,0,0,1,10.9937,5.9994)\"></circle><circle cx=\"495.5\" cy=\"122.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_15_endpoint_1\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint down sub\" transform=\"matrix(1,0,0,1,10.9937,3)\"></circle><circle cx=\"484.5\" cy=\"111.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_15_endpoint_2\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint left sub\" transform=\"matrix(1,0,0,1,-14.9643,4.4997)\"></circle><circle cx=\"506.5\" cy=\"111.34375\" r=\"5\" stroke=\"#000000\" fill=\"#ffffff\" id=\"drup_elem_15_endpoint_3\" style=\"stroke-width: 1; opacity: 0;\" class=\"endPoint right sub\" transform=\"matrix(1,0,0,1,36.9519,4.4997)\"></circle><text x=\"495.5\" y=\"111.34375\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\" transform=\"matrix(1,0,0,1,10.9569,4.4997)\">|</text></g><g id=\"drup_elem_16\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"342.5\" x2=\"344.5\" y1=\"24.34375\" y2=\"241.34375\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"343.5\" y=\"132.84375\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_17\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><line x1=\"314.5\" x2=\"669.5\" y1=\"214.34375\" y2=\"216.34375\" fill=\"#ffffff\" stroke=\"#000000\" vector-effect=\"non-scaling-stroke\" style=\"stroke-width: 1;\" class=\"core alignable sub egal-line\"></line><text x=\"492\" y=\"215.34375\" style=\"font-size: 20px; text-anchor: middle; alignment-baseline: central; opacity: 0;\" class=\"egal-label sub\">|</text></g><g id=\"drup_elem_18\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"682.5\" y=\"214.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_19\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"642.5\" y=\"187.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_20\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"687.5\" y=\"240.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_21\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"715.5\" y=\"222.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_22\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"708.5\" y=\"205.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_23\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"776.5\" y=\"240.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central; font-size: 20px;\"></text></g><g id=\"drup_elem_24\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"776.5\" y=\"240.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central; font-size: 20px; visibility: visible; opacity: 1;\" data-src=\"w1\" transform=\"matrix(1,0,0,1,-74,-21)\">w1</text></g><g id=\"drup_elem_25\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"788.5\" y=\"249.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_26\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"775.5\" y=\"240.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_27\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"776.5\" y=\"223.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_28\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"746.5\" y=\"213.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central; font-size: 20px;\"></text></g><g id=\"drup_elem_29\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"339\" y=\"12.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_30\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"202\" y=\"111.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_31\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem\"><text x=\"338\" y=\"25.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central;\"></text></g><g id=\"drup_elem_32\" first-frame=\"1\" last-frame=\"1\" class=\"drupElem egal-select\"><text x=\"338\" y=\"27.34375\" class=\"core alignable sub egal-label\" style=\"text-anchor: middle; alignment-baseline: central; font-size: 20px;\" data-src=\"w2\" transform=\"matrix(1,0,0,1,4,-15)\">w2</text></g></svg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't like shapes like this. We want a circle instead of an ellipse, so that the gradient points directly to the minimum. \n",
    "\n",
    "Let's think about what produces this ellipses. Say a neuron has two inputs and the following training cases\n",
    "$$\n",
    "x_1 = .1, x_2 = -10, y = 1 \\\\\n",
    "x_1 = .1, x_2 = 10, y = -1\n",
    "$$\n",
    "This neuron is much more sensible to the second input than the first one. Specifically, changing $w_2$ will affect the cost $100$ times more than changing $w_1.$ Thus, we get a shape like the one in the diagram above.\n",
    "\n",
    "[TODO: say that the same happens when we have x1 and x2 as axes]\n",
    "\n",
    "When we see the diagram above and notice that the component of the gradient in the w1-axis is pretty low, we could say \"easy, let's increase the learning rate!\" The problem there is that this would make things worse, because the compontent of the gradient in the w2-axis will be bigger and will end in having a lot of oscillations. From this perspective, it makes sense to have an different learning rate for each axis.\n",
    "https://distill.pub/2017/momentum/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights\n",
    "The set of weights that connect layer $l$ to layer $l + 1$ have to be random. Otherwise, if all the weights are the same (in particular, if all the weight are zero) the gradient will be the same for every neuron in the layer $l$ and thus all neurons will compute the same function forever. An alternative approach will be to add noise to the gradient [idea: try this]\n",
    "\n",
    "What happens if we have a neuron that has 1000 incoming weights? Even if the input is normalized (ie mean=0 variance=1) we will need to make the weights small, otherwise the variance of $\\sum_i^n w_ix_i$ will be too large. Specifically, the variance of that sum is directly proportional to (a) the variance of the weights, (b) the variance of the inputs, and (c) the amount of connections. Let's say we have (b) and (c) fixed. Then, we want to find the optimal value for (a). \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Var(\\sum_iw_ix_i) &= \\sum_iVar(w_ix_i) \\tag {1} \\\\\n",
    "&= \\sum_iVar(w_i)Var(x_i) \\tag {2} \\\\\n",
    "&= nVar(w)Var(x) \\tag {3} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In (2) we used the fact that $w_i$ and $x_i$ are independent and have zero mean [link to prob theory]. In (3) we used the fact that all variables $w_i$ are identically distributed (and the same applies to $x_i.$)\n",
    "\n",
    "Thus, if we want $Var(\\sum_iw_ix_i) = 1,$ then the best value for $Var(w)$ is $1/(n \\cdot Var(x)).$ If we know that the input has unit variance, then the best value is $1/n.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0448629656936872"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "trials = []\n",
    "for _ in range(5000):\n",
    "    x = np.random.randn(n) * 2 #Var(x) = 4\n",
    "    w = np.random.randn(n) / 20 #Var(w) = 1/400\n",
    "    trials.append(sum(w * x))\n",
    "np.var(trials) #Var(wx) = n * var(x) * var(w) = 100 * 4 * 1/400 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we multiply a random variable by $k$, its variance gets multiplied by $k^2.$ To understand this, let's say the mean was $a$ and there was another point at $b.$ Now, those points arrive in $ka$ and $kb.$ The distance between them now is $kb - ka = k \\cdot (b - a).$ Before that, the distance was $b - a.$ So, the distance increases by $k.$ But the variance measures the squared distance. Thus, the contribution to the variance for that point is $k^2$ times more than its contribution before. \n",
    "\n",
    "#### Inputs\n",
    "Normalize. Decorrelat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost functions revisited\n",
    "{TODO: cross entropy}\n",
    "#### Softmax function\n",
    "Question: does the softmax change the order of the probabilities?\n",
    "\n",
    "#### Locally weighted algorithm\n",
    "The training data is noisy. Thus, we don't want to fit outliers, because they may not represent the real distribution of the data we are trying to model. One definition for the error is\n",
    "$$E(w) = \\sum_i(y_i - w^Tx_i)^2$$\n",
    "Now, we want to find a way to give less importance to points that are outliers and more importance to points near the mean.\n",
    "$$E(w) = \\sum_i \\theta_i(y_i - w^Tx_i)^2$$\n",
    "For $\\theta$ we want an always-positive value. Also, we want a high value if $x_i - mean(x)$ is small, and we want a small value if $x_i - mean(x)$ is high. Note that we care about the absolute value of the difference between $x_i - mean(x)$ that's why we have the squared term.\n",
    "$$\\theta = exp(-(x_i - mean(x))^2)$$\n",
    "Now, the distribution of the weights is fixed. That is, with the expression above for $\\theta,$ we can't change from caring a lot about the values that are near the mean, to caring the same for every value. That's why we add a parameter. Note that as $\\tau$ tends to inifinity, $\\theta$ tends to 1 and we recover our original erorr term.\n",
    "$$\\theta = exp\\bigg(-\\frac{(x_i - mean(x))^2}{2\\tau^2}\\bigg)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting/overfitting/bias/variance\n",
    "Overfitting: when the nn captures regularities in the trani data not present in test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural gradient: when we tune our parameters with gradient descent (the changes being given by backprop), the distribution of the output of our net before and after the gradient descent step could change a lot. That is, the KL Divergence of the net before and after could change a lot or remain very similary. With the natural gradient, we see every change in the parameters that changes the KL divergence by a given constant, and over all those sets of parameters, we select the set that minimizes the loss fn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms\n",
    "Level curves: level curves are a way to represent 3D plots in 2D. In these plots, for every value $k$ in a set of values, we draw a curve that goes through every point $x, y$ in the function where $f(x, y) = k.$ It's good if the values in the set have the same distance between them (eg set = {0, 10, 20, 30}) so we can get an idea of the 3D shape. \n",
    "\n",
    "Types of function from set A to set B:\n",
    "* bijection: every point in A is paired with exactly one point in B, and every point in B is paired with one point in A.\n",
    "* injection: every point in A is paired with exactly one point in B.\n",
    "* surjection: every point in B is paired with at least one point in A.\n",
    "\n",
    "Fourier transform: convert a signal to a weighted sum of sines and cosines.\n",
    "\n",
    "When we have derivative(integral(f)) and the limits of the integral don't depend on the parameters of the functino, then we can swap integral and derivative (derivative(integral(f) = integral(derivative(f))). If they depend on the parameters, then we have to add extra terms. It makes sense because int(deriv(f)) seems to be losing the constant term in comparison with deriv(int(f))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
