{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Discriminative\n",
    "In discriminative algorithms, we are trying to model the probability of each class given the input, $P(y|x).$ We are asking ourselves: given that I saw this image x, what's the probability that it's a cat, $P(Y=cat|X=x)$?\n",
    "\n",
    "In training time, we select the probability function that gives us the greatest likelihood of having seen the training data. \n",
    "\n",
    "$$\\theta = argmax_\\theta \\prod_i^m P(Y = y^{(i)}|X = x^{(i)}; \\theta)$$\n",
    "\n",
    "The probability function with the most chance of being the one that produced the training data is the probability function that gives us more chance of producing the training data. Say we have a probability function $f$ and another $g.$ If $f$ produces the data we've seen $99\\%$ of the time, and $g$ produces the data $1\\%$ of the time, then chances are that the data was produced by $f.$ (We could have been produced by $g,$ but it's far less probable.)\n",
    "\n",
    "What discriminative algorithms do is to draw boundaries between classes. This is more clear when a model needs to output a specific class in prediction time: there is a boundary when we pass from 30% cat and 29% bird to 30% cat and 31% bird. In the first case, the model says cat. In the second case, it says bird. It's in that place where we have the boundary.\n",
    "\n",
    "## Generative\n",
    "Humans don't just know to discriminate birds from cats; we can also generate drawings of birds and cats. So, there is something else there. I think that only knowing the boundaries has a lack of understanding of how the data works. Understanding is important because we can easily transfer the knowledge from one type of tasks to another. But if our model doesn't understand, it will see whatever it learns as a set of arbitrary rules. \n",
    "\n",
    "So, we want a model that draws cats, birds, and transformers. In particular, we want to tell the model to give us images of cats, images of birds, and images of transformers. That means our model needs to predict $P(X = x|Y = cat),$ $P(X = x|Y = bird),$ and $P(X = x|Y = transformer).$ We can think of $x$ as each possible arrangement of pixels (ie each possible image.)[1] \n",
    "\n",
    "In prediction time we are given an image $x$ and we want to predict the class. We could just go over the three probability functions described above, evaluate them, and see which has the greatest value. But there is a catch. Say the distribution is such that there are only a few images of transformers. And also say that the variable $x_1$ has an image of a transformer. Now, say that there is a photo facing down that we know it has a transformer. As there are only a few transformer's images, the probability that the image facing down is $x_1$ is high (ie $P(X=x_1|Y=transformer)$ is big.) But wait, that doesn't mean that if we receive $x_1$ we should give a high chance to the transformers. We have to take into account that it's very improbable to see an image of a transformer.\n",
    "\n",
    "# Notes\n",
    "[1] In the future, we will need to assume that something is independent, otherwise there are too many images to process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
